{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VGGNet\n"
      ],
      "metadata": {
        "id": "dN3ZQlftiUvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 목표\n",
        "-----\n",
        "- VGGNet을 사용하여 이미지를 학습하고 10개의 카테고리를 갖는 이미지를 분류하는 이미지 분류기를 생성한다. (데이터셋: [CIFAR](https://pytorch.org/vision/0.9/datasets.html#cifar))\n",
        "- Pre-training 모델의 사용방법을 이해한다."
      ],
      "metadata": {
        "id": "IZQUXbStQ1_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 정의\n",
        "----\n",
        "- VGGNet 구조 살펴보기\n",
        "\n",
        "\n",
        "\n",
        "![VGG](https://miro.medium.com/max/1100/0*6VP81rFoLWp10FcG)"
      ],
      "metadata": {
        "id": "lE19ubUbSYGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주요 코드\n",
        "----\n"
      ],
      "metadata": {
        "id": "0sQ6EUbbTTJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. VGGNet\n",
        "\n",
        "```\n",
        "# Model\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 360),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(360, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    # 'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tzyFuYp3xo97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Pretrained model\n",
        "\n",
        "```\n",
        "from torchvision import models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.to(DEVICE)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr = LEARNING_RATE, momentum=0.9)\n",
        "```"
      ],
      "metadata": {
        "id": "zxJSyB_7xaym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR Classifier(VGGNet)\n",
        "----\n",
        "CIFAR 데이터셋을 사용하여 이미지에 포함된 object가 무엇인지 분류하는 이미지 분류기를 생성해봅니다.\n"
      ],
      "metadata": {
        "id": "TaYfE-bVTXO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step1] Load libraries & Datasets"
      ],
      "metadata": {
        "id": "d6HMrwnVi_GJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdsAY_OFiAwA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.transforms.functional import to_pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step2] Data preprocessing\n",
        "\n",
        "불러온 이미지의 증강을 통해 학습 정확도를 향상시키도록 합니다.\n",
        "\n",
        "* RandomCrop\n",
        "* RandomHorizontalFlip\n",
        "* Normalize"
      ],
      "metadata": {
        "id": "0eVZEhR3FtVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),   \n",
        "])\n",
        "\n",
        "train_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")\n",
        "\n",
        "test_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")"
      ],
      "metadata": {
        "id": "7vpIPI097K-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step3] Set hyperparameters"
      ],
      "metadata": {
        "id": "DjzgqxxYRZ21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using Device:\", DEVICE)"
      ],
      "metadata": {
        "id": "pDqQL8xBdXfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step4] Create DataLoader"
      ],
      "metadata": {
        "id": "plROYXHy95Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_img, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = DataLoader(test_img, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "7Vg9INIm94Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step5] Set Network Structure"
      ],
      "metadata": {
        "id": "tpRGRkTXjJB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 360),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(360, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "BJ9iQln4FEhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step6] Create Model instance"
      ],
      "metadata": {
        "id": "svcCPRGxF5ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG('VGG16').to(DEVICE)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "FDgZ56RzGAN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step7] Model compile"
      ],
      "metadata": {
        "id": "gPwh-CXVGtBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9)"
      ],
      "metadata": {
        "id": "RwM8c2TdGseO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step8] Set train loop"
      ],
      "metadata": {
        "id": "mz2OUt7nHAcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    \n",
        "    size = len(train_loader.dataset)\n",
        "    \n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "        pred = model(X)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss: {loss:>7f}  [{current:>5d}]/{size:5d}')"
      ],
      "metadata": {
        "id": "ikRtBCZAG_iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step9] Set test loop"
      ],
      "metadata": {
        "id": "AYsz8VDYH-hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")"
      ],
      "metadata": {
        "id": "Sn1ny3mCH92_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step10] Run model"
      ],
      "metadata": {
        "id": "7ecAzx8DI_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH) :\n",
        "    print(f\"Epoch {i+1} \\n------------------------\")\n",
        "    train(train_loader, model, loss, optimizer)\n",
        "    test(test_loader, model, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "2OtZ9fhmJBeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR Classifier(Pretrained VGGNet)\n",
        "----\n",
        "ImageNet 데이터로 학습한 VGGNet을 사용하여 주어진 데이터 셋에서 사용할 수 있도록 Fine tuning 해봅니다.\n"
      ],
      "metadata": {
        "id": "lFVP28sGSmIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.to(DEVICE)\n",
        "print(vgg16)"
      ],
      "metadata": {
        "id": "2_t37NcbSqnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier[6].out_features = 10\n",
        "\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False    "
      ],
      "metadata": {
        "id": "sOnUKnv8We0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr = LEARNING_RATE, momentum=0.9)"
      ],
      "metadata": {
        "id": "rDJ-P97FYRg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH) :\n",
        "    print(f\"Epoch {i+1} \\n------------------------\")\n",
        "    train(train_loader, vgg16, loss, optimizer)\n",
        "    test(test_loader, vgg16, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "HoDA2WbOUr-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5ffFDJ6nOgx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}